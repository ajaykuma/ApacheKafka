#To setup a distributed kafka cluster we need to setup 'zookeeper ensemble' and then have our kafka brokers connect
 to this ensemble.

Step 1:
Setup a Zookeeper ensemble (cluster of zookeeper with atleast 3 zk peers)
----------------------------------
#Setup atleast 3 machines (ubuntu /centos) within VMbox
centos(n1,n2,n3) as in our case

Centos Nodes:
Now on each machine
--- to login as root
$sudo su 

---update and install necessary packages
$yum update -y
$yum install vim -y
$yum install wget -y
$yum install openssh-server -y
$yum update -y

---disable firewall
$systemctl status firewalld
$systemctl stop firewalld
$systemctl disable firewalld

---get your ipaddress
$ip address 

---get your hostname
$hostname 

update your /etc/hosts
127.0.0.1     localhost
ipaddress1     hostname1
ipaddress2    hostname2
ipaddress3    hostname3

update hostnames/check hostnames
cat /etc/hostname

sudo visudo and add 'nif' as user next to root where you see ALL
This will give your user sudo access

$java -version
#if java installed,update java to be able to use JPS command

$yum install java-1.8.0-openjdk-devel

update your java path in your user's .bashrc
(ex: my user is 'nif')
su - nif

vi .bashrc
export JAVA_HOME=/usr/lib/jvm/jdk****
export PATH=$PATH:$JAVA_HOME/bin

save your .bashrc
refresh it by ---> source .bashrc

$java -version ( does it show your java version)

Now Generate ssh keys for your user on ubuntu

Commands:
--------------
---Note** we are logged in as 'nif'
To have SSH access across machines
1.generate ssh keys using 
$ssh-keygen -t rsa -P ""

2.Distributing ssh public keys to other machines
----------------------
$nif$n1:ssh-copy-id -i $HOME/.ssh/id_rsa.pub nif@n2
$nif$n1:ssh-copy-id -i $HOME/.ssh/id_rsa.pub nif@n3
$nif$n2:ssh-copy-id -i $HOME/.ssh/id_rsa.pub nif@n1
$nif$n2:ssh-copy-id -i $HOME/.ssh/id_rsa.pub nif@n3
$nif$n3:ssh-copy-id -i $HOME/.ssh/id_rsa.pub nif@n1
$nif$n3:ssh-copy-id -i $HOME/.ssh/id_rsa.pub nif@n2

3.To enable SSH access to your local machine with this newly created key
----------------------------------------
to add the xxxx@master’s public SSH key (which should be in $HOME/.ssh/id_rsa.pub) 
to the authorized_keys file of xxxx@master(in this user’s $HOME/.ssh/authorized_keys)
n1$cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
n2$cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
n3$cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys

Test your ssh access...

#Setup Zk ensemble
---Download zookeeper package from http://archive.apache.org/dist/
zookeeper-3.4.6.tar.gz  

---Download on each node 
   or download on 1st node and then copy(scp) to each node 
   [nif$n1>scp /home/nif/Downloads/zookeeper-3.4.6.tar.gz nif@n2:/home/nif/Downloads/]
   [nif$n1>scp /home/nif/Downloads/zookeeper-3.4.6.tar.gz nif@n3:/home/nif/Downloads/]

#check in nodes in /usr/local if it already has zookeeper related directory
$cd /usr/local
$ls -all

#if not..

---After downloading repeat these steps on each node (say n1,n2,n3)

su - root
$cd /usr/local
$tar -xvf /home/nif/Downloads/zookeeper-3.4.6.tar.gz
$ln -s zookeeper-3.4.6 zookeeper
$chown -R nif:nif zookeeper*

$su - nif
#check if .bashrc has paths for java & zookeeper 
#if not then update..
$vi .bashrc
export JAVA_HOME=/usr/lib/jvm/jdk****
export PATH=$PATH:$JAVA_HOME/bin
export ZOOKEEPER_HOME=/usr/local/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin
--save

$source .bashrc

#if already set in one machine, scp .bashrc to other machines
nif$n1>scp .bashrc nif@n2:/home/nif
nif$n2>scp .bashrc nif@n3:/home/nif

---updating zookeeper configs on each machine
$cd /usr/local/zookeeper/conf
$cp zoo_sample.cfg zoo.cfg

--we need to edit zoo.cfg in each machine
--explaination

[tickTime: in milliseconds unit of times for initLimit
 initLimit:zookeeper uses these unit of times to connect to the cluster
 syncLimit: time to come back in sync or peer will out of cluster
  dataDir: cluster related and clients connected to zk cluster data
  clientPort: how clients connect to zk
  maxClientCnxns: how many cleints can connect
  4lw.commands.whitelist=* : enabling 4 letter words such as stat,dump
  2888: port for peers to communicate
  3888: for leader election]

--explaination ends.

$vi zoo.cfg

	tickTime=2000
	dataDir=/tmp/zookeeper
	clientPort=2181
	initLimit=5
	syncLimit=2
	server.1=n1:2888:3888
	server.2=n2:2888:3888
	server.3=n3:2888:3888

---we specified the servername as 'hostname' i.e. say 'n1 , n2, n3',
   with quorum & leader election ports (i.e. 2888:3888, 2888:3888, 2888:3888) 
---port 2888 for quorum peers to communicate to each other
---port 3888 for leader election

#remember to copy zoo.cfg to /usr/local/zookeeper/conf/ in each machine or edit manually
#note you are in /usr/local/zookeeper/conf

nif$n1>scp zoo.cfg nif@n2:/usr/local/zookeeper/conf/
nif$n1>scp zoo.cfg nif@n3:/usr/local/zookeeper/conf/

---Every machine that is part of the ZooKeeper ensemble needs to know about every other machine in the ensemble. 
   As such, we need to attribute a server id to each machine by creating a file named myid, one for each server,
   which resides in that server's data directory, as specified by the configuration file parameter dataDir.

---Note: More information about ZooKeper configuration settings can be found in the ZooKeeper Getting Started Guide.

#on node1
n1$zkServer.sh start
>jps
echo 1 > /tmp/zookeeper/myid
#if zookeeper directory doesn't exist in /tmp, create it.
n1$zkServer.sh start

#on node2
n2$zkServer.sh start
>jps
echo 2 > /tmp/zookeeper/myid
#if zookeeper directory doesn't exist in /tmp, create it.
n2$zkServer.sh start

#on node3
n3$zkServer.sh start
jps
echo 3 > /tmp/zookeeper/myid
#if zookeeper directory doesn't exist in /tmp, create it.
n2$zkServer.sh start

ZooKeeper Startup
check if ZooKeeper was started on each host


#check status of which peer acts as leader/follower
$echo stat | nc n1 2181
$echo stat | nc n2 2181
$echo stat | nc n3 2181

(optional)
#We can also start zookeepers in foreground as follows
n1$zkServer.sh start-foreground
n2$zkServer.sh start-foreground
n3$zkServer.sh start-foreground

Step 2:
Now that zookeeper processes are running on each machine, we need to setup kafka 
--Download kafka tar from archive.apache.org on each node
http://archive.apache.org/dist/kafka/2.2.1/kafka_2.11-2.2.1.tgz

$sudo su
$cd /usr/local
$tar -xvf /home/nif/Downloads/kafka_2.11-2.2.1.tgz
$ln -s kafka_2.11-2.2.1 kafka
$chown -R nif:nif kafka*

---update path in .bashrc

$su - nif
$vi .bashrc
export JAVA_HOME=/usr/lib/jvm/jdk****
export PATH=$PATH:$JAVA_HOME/bin
export ZOOKEEPER_HOME=/usr/local/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin
export KAFKA_HOME=/usr/local/kafka
export PATH=$PATH:$KAFKA_HOME/bin

#if already set in one machine, scp .bashrc to other machines
nif$n1>scp .bashrc nif@n2:/home/nif
nif$n2>scp .bashrc nif@n3:/home/nif

#on each node while logged in as 'nif'
$source .bashrc

--edit /usr/local/kafka/config/server.properties in each machine..

on node1:
broker.id=0
listeners=PLAINTEXT://n1:9092
log.dirs=/usr/local/kafka/kafka-logs
zookeeper.connect=n1:2181,n2:2181,n3:2181

on node2:
broker.id=1
listeners=PLAINTEXT://n2:9092
log.dirs=/usr/local/kafka/kafka-logs
zookeeper.connect=n1:2181,n2:2181,n3:2181

on node3:
broker.id=2
listeners=PLAINTEXT://n3:9092
log.dirs=/usr/local/kafka/kafka-logs
zookeeper.connect=n1:2181,n2:2181,n3:2181

on each node:
mkdir /usr/local/kafka/kafka-logs


on node 1:
kafka-server-start.sh /usr/local/kafka/config/server.properties

on node 2:
kafka-server-start.sh /usr/local/kafka/config/server.properties

on node 3:
kafka-server-start.sh /usr/local/kafka/config/server.properties

To create Topic:
kafka-topics.sh --bootstrap-server n1:9092 --create --topic Test1 --partitions 3 --replication-factor 3
kafka-topics.sh --bootstrap-server n1:9092 --describe --topic Test1

echo dump | nc n1 2181 | grep brokers

Making one of the broker as controller node
#check which broker has controller directory
echo dump | nc n1 2181











