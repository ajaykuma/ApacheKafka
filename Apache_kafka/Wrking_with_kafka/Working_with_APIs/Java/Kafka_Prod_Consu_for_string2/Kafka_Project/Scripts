--start zookeeper
> C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>zookeeper-server-start.bat ..\\..\\config\\zookeeper.properties

--start kafka broker
> C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-server-start.bat ..\\..\\config\\server.properties

--check cluster
C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-topics.bat --list --bootstrap-server localhost:9092

--create a topic
C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-topics.bat --create --topic Test1 --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

--describe topic
C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-topics.bat --describe --bootstrap-server localhost:9092
Topic:Test1     PartitionCount:3        ReplicationFactor:1     Configs:segment.bytes=1073741824
        Topic: Test1    Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: Test1    Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: Test1    Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        
--pushing data into topics
--we can use our producer application or from command line
C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-console-producer.bat --topic Test1 --broker-list localhost:9092 < I:\\GitContent\\Datasets\\Datasets\\Bank_full.csv

--Accessing offsets per partition and accessing messages from specific offset
C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-run-class.bat kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic Test1
Test1:0:15071
Test1:1:15070
Test1:2:15071

C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-console-consumer.bat --topic Test1 --bootstrap-server localhost:9092 --offset 15069 --partition 0
45208,71,retired,divorced,primary,no,1729,no,no,cellular,17,nov,456,2,-1,0,unknown,yes
45211,37,entrepreneur,married,secondary,no,2971,no,no,cellular,17,nov,361,2,188,11,other,no

C:\Users\Win10\Downloads\kafka\kafka_2.11-2.2.1\bin\windows>kafka-console-consumer.bat --topic Test1 --bootstrap-server localhost:9092 --offset 15069 --partition 0 --property print.timestamp=true
CreateTime:1644329887841        45208,71,retired,divorced,primary,no,1729,no,no,cellular,17,nov,456,2,-1,0,unknown,yes
CreateTime:1644329887841        45211,37,entrepreneur,married,secondary,no,2971,no,no,cellular,17,nov,361,2,188,11,other,no

#Notes:
Every log composing a partition (usually there will be a single one) is composed of multiple segments, ordered from the oldest 
to the most recent ones. Every segment has its data file where all records are stored and in addition to it, 
it also has 3 different indexes. Aborted transactions index takes care of records visibility during the transaction. 

Timestamp index is a mapping between records timestamps and their positions whereas offset index is the mapping between offsets
 and their positions in the files. 
The entries in the indexes aren't added for every single record added to the log. The frequency of updates is controlled by 
index.interval.bytes property which by default is 4096. It means that Apache Kafka will add new entries to the offset and 
timestamp indexes every 4096 bytes.








